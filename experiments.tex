% The Experiments of the study should be laid out in a series of declarative paragraphs. Only results essential to establish the main points of the work should be included. Often the reporting of the results can be clearer if broken down into subsections. All figures and tables must be cited in the text and must be numbered in the order of their text citation. Figure legends should be self-explanatory, without referring to the text. They should identify the material that is being illustrated, what is shown, and its significance. Each table should be identified by number and should have a title. This section should not include long passages about the rationale of the experiments (which belong in the Introduction), or the methods used (which belong in the Material and Methods), nor should it include justification or discussion of the results (which belong in the Discussion section).
\chapter{Experiments}
\label{sec:experiments}

We perform these experiments to showcase that we can indeed get semantically expressive creations with our proposed formulation.


\section{Environments}

We use two custom environments in the following experiments which allow for rich creative expression.

\subsection{ShapeGridWorld}
\label{sec:sgw}
The ShapeGridWorld (SGW) is a pixel grid environment where the agent can draw on the grid by moving pixels around.
This is reminiscent of the pin-board platform used in the free play study conducted by \citet{diggs}.
By setting the pixels in a specific layout, the agent can draw a variety of shapes on the grid.
This environment was adapted from the pixel grid environment used in the work by \citet{rair} with some modifications summarised in the appendix \ref{sec:sgw-details}.

\subsection{Tangram}
\label{sec:tangram}
Tangram is a puzzle environment consisting of a canvas and seven geometric shapes -- five right triangles, one square, and one parallelogram.
Even though the shapes are simple, they can be arranged in different configurations to create expressive abstract patterns.
This environment was developed specifically for this work and more details are given in the appendix \ref{sec:tangram-details}.

% - Comparing CLIP Models
% - CLIP on sketches
%     - Effect of the number of categories
%     - CLIP on MNIST
% - CLIP on SGW (since it’s reminiscent of the pinboard study)
%     - Registration technique — move to appendix
%     - Effect of resolution
%     - Effect of using general vs specific labels
%     - Effect of changing prefix
%     - Effect of changing suffix
%     - Effect of inversions
%     - Jibberish and adding concepts in post-suffix (WaffleCLIP)
% - CLIP on rollouts
%     - [Comparing CLIP Models](https://www.notion.so/Comparing-CLIP-Models-ae60ab2be1f44dbd9d1b5db87efa5862?pvs=21)
% - Simulations on SGW with Ground Truth Model
%     - +- RaIR
% - Problems with CLIP
%     - Sparse rewards
%     - Inference noise — confidence in random images
% - Closeness rewards
% - Tangram
%     - Effect of post-suffix
%     - Effect of negative embeddings
%     - Effect of image operations
%         - Shearing
%         - Hatching
% - Simulations on Tangram with Ground Truth Model
%     - With and without RaIR

\section{Simulations on SGW with Ground Truth Model}

\section{Prompt Engineering with CLIP}
\label{sec:prompt-engineering-experiments}
\cite{waffleclip} found that the exact structure of the phrase, and even tailing it a random string of jibberish, can affect the reward. 
